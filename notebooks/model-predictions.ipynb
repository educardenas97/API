{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/educardenas97/API/blob/master/notebooks/model-predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#    https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "l6nGHoRo3mym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI Knowledge Base model predictions\n",
        "\n",
        "To run this notebook, make sure you have uploaded at least one document into your knowledge base.\n",
        "\n",
        "> 猸锔 If you haven't, follow the [**Uploading documents and query model** tutorial](https://console.cloud.google.com/products/solutions/deployments?walkthrough_id=panels--sic--generative-ai-knowledge-base_toc).\n",
        "\n",
        "Before you begin, make sure all the dependencies are installed."
      ],
      "metadata": {
        "id": "PQFrKlY5Yi2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform google-cloud-firestore"
      ],
      "metadata": {
        "id": "W9C3mHjIiZn1",
        "outputId": "c9784442-04df-4434-92ca-2301f8254d50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.70.0)\n",
            "Requirement already satisfied: google-cloud-firestore in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.13.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.9.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-firestore) (2.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "A **Large Language Model (LLM)** can be very good at answering general questions.\n",
        "But it might not do as well to answer questions from your documents on its own.\n",
        "\n",
        "The LLM will answer only from what it learned from its _training dataset_.\n",
        "Your documents might include information or words that weren't on that dataset.\n",
        "Or they might be used in a different or more specialized context.\n",
        "\n",
        "This is where **Vector Search** comes into place.\n",
        "Each time you upload a document, the Cloud Function webhook processes it.\n",
        "When a document is processed, each individual page is _indexed_.\n",
        "This allows us to not only find documents, but the specific pages.\n",
        "\n",
        "The relevant pages can then be used as _context_ for the LLM to answer the question.\n",
        "This _grounds_ the model to answer questions based on the documents only.\n",
        "Without this, the model might give wrong answers, or _hallucinations_."
      ],
      "metadata": {
        "id": "tXeqwSesfIjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My Google Cloud resources\n",
        "\n",
        "Fill in your project ID, the\n",
        "[Google Cloud location](https://cloud.google.com/about/locations)\n",
        "you want to use, and your\n",
        "Vector Search index endpoint ID.\n",
        "If you followed the tutorial, the deployed index ID should be `deployed_index`, otherwise change it to the ID you chose.\n",
        "\n",
        "You can find your Vector Search index endpoint ID in the [Index endpoints tab](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints).\n",
        "\n",
        ">  The Vector Search index endpoint ID looks like a number, like `1234567890123456789`.\n",
        "\n",
        "Run the following cell to set up your resources and authenticate to your account."
      ],
      "metadata": {
        "id": "nZeNBhYcknZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from google.colab import auth\n",
        "\n",
        "project_id = \"legal-bot-433022\" # @param {type:\"string\"}\n",
        "location = \"us-central1\" # @param {type:\"string\"}\n",
        "index_endpoint_id = \"2675397663402229760\" # @param {type:\"string\"}\n",
        "deployed_index_id = \"knowledge_base_index_deplo_1731351552266\" # @param {type:\"string\"}\n",
        "\n",
        "auth.authenticate_user(project_id=project_id)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4EctJVdOj0MY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is to initialize the Vertex AI client library using the location of your choice."
      ],
      "metadata": {
        "id": "1P7apRRQabq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "vertexai.init(location=location)\n",
        "aiplatform.init(location=location)"
      ],
      "metadata": {
        "id": "nkPB50oClSD6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get text embeddings\n",
        "\n",
        "You can use the Gecko model to get embeddings from text.\n",
        "For more information, see the\n",
        "[Get text embeddings](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings)\n",
        "page."
      ],
      "metadata": {
        "id": "5rDc4RataxgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
        "\n",
        "def get_text_embedding(text: str) -> list[float]:\n",
        "    task = 'RETRIEVAL_DOCUMENT'\n",
        "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko\")\n",
        "    return model.get_embeddings([TextEmbeddingInput(text, task)])[0].values\n",
        "\n",
        "\n",
        "# Convert the question into an embedding.\n",
        "#question = \"Leyes sobre el impuesto selectivo al consumo\"\n",
        "question = \"驴Qu茅 dice La Ley N掳 6380/2019?\"\n",
        "question_embedding = get_text_embedding(question)\n",
        "print(f\"Embedding dimensions: {len(question_embedding)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ97FaoBdO_8",
        "outputId": "9a1c78d1-9b8e-4741-bd52-2eb7c76517f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dimensions: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find document context\n",
        "\n",
        "All the documents you have processed have been indexed into your Vector Search index.\n",
        "You can query for the closest embeddings to a given embedding from your Vector Search index endpoint.\n",
        "\n",
        ">  If you haven't processed any documents yet, you won't get any results."
      ],
      "metadata": {
        "id": "vnJfXPXAb-1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import groupby\n",
        "\n",
        "def find_document(question: str, index_endpoint_id: str, deployed_index_id: str) -> tuple[str, int]:\n",
        "    # Get embeddings for the question.\n",
        "    embedding = get_text_embedding(question)\n",
        "\n",
        "    # Find the closest point from the Vector Search index endpoint.\n",
        "    endpoint = aiplatform.MatchingEngineIndexEndpoint(index_endpoint_id)\n",
        "    point = endpoint.find_neighbors(\n",
        "        deployed_index_id=deployed_index_id,\n",
        "        queries=[embedding],\n",
        "        num_neighbors=1,\n",
        "    )[0][0]\n",
        "\n",
        "    # Get the document name and page number from the point ID.\n",
        "    (filename, page_number) = point.id.split(':', 1)\n",
        "    return (filename, int(page_number))\n",
        "\n",
        "# Query the Vector Search index for the most relevant page.\n",
        "(filename, page_number) = find_document(question, index_endpoint_id, deployed_index_id)\n",
        "print(f\"{filename=} {page_number=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxLfbjSLeaIh",
        "outputId": "04ea3769-3d04-4fd3-ba12-9cf2f2e70e4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename='RESOLUCIN N掳 07 - 2024.pdf' page_number=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get document text\n",
        "\n",
        "When documents were processed, their text was stored in Firestore as well.\n",
        "The Vector Search query returned the relevant documents with their page numbers.\n",
        "With this you can download the document's pages and give only the most relevant page to the model."
      ],
      "metadata": {
        "id": "BzRC13xdeK5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import firestore\n",
        "\n",
        "def get_document_text(filename: str, page_number: int) -> str:\n",
        "    db = firestore.Client(database='knowledge-base-database')\n",
        "    doc = db.collection(\"documents\").document(filename)\n",
        "    return doc.get().get('pages')[page_number]\n",
        "\n",
        "# Download the document's page text from Firestore.\n",
        "context = get_document_text(filename, page_number)\n",
        "print(f\"{context[:1000]}\\n...\\n...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTJqJg1dfRY5",
        "outputId": "7440db40-cdd3-4ee4-f583-66151186f567"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: RESOLUCIO?N N掳 07 - 2024\n",
            "RESOLUCIN GENERAL DNIT N掳 07 / 2024\n",
            "POR LA CUAL SE DISPONEN MEDIDAS ADMINISTRATIVAS RELACIONADAS A LA CONFIRMACIN\n",
            "Asunci贸n, 27 de marzo de 2024\n",
            "VISTO: El Libro V de la Ley N掳 125/1991 芦Que establece el Nuevo R茅gimen Tributario禄 y sus modificacio\n",
            "CONSIDERANDO: Que con el objeto de estandarizar la informaci贸n a ser presentada a la Administraci贸n\n",
            "POR TANTO,\n",
            "EL DIRECTOR NACIONAL DE INGRESOS TRIBUTARIOS\n",
            "RESUELVE:\n",
            "Art铆culo 1掳. - Establecer que excepcionalmente hasta el 31 de agosto de 2024 no constituir谩 incumplimient\n",
            "a. La falta de confirmaci贸n del tal贸n de presentaci贸n del registro de comprobantes correspondiente a los e\n",
            "b. La falta de confirmaci贸n del tal贸n de presentaci贸n del registro de comprobantes correspondiente a los p\n",
            "Durante dicho periodo igualmente se seguir谩 recibiendo el registro de los comprobantes y la confirmaci贸n\n",
            "Art铆culo 2掳. - Establecer que hasta el 31 de agosto de 2024 no ser谩 aplicable la sanci贸n por contravenci贸n\n",
            "Art铆culo 3掳. - Dispone\n",
            "...\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ask a foundational model\n",
        "\n",
        "With the relevant context ready, you can now make a _prompt_ that includes both the context and the question.\n",
        "\n",
        "Here's Gemini's response.\n",
        "Note that Gemini responds in [Markdown](https://www.markdownguide.org)."
      ],
      "metadata": {
        "id": "5NB2BO0tSBFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "# Ask the foundational model.\n",
        "model = GenerativeModel(\n",
        "    model_name=\"gemini-1.0-pro-002\",\n",
        "    system_instruction=context,\n",
        ")\n",
        "answer = model.generate_content(question).text\n",
        "\n",
        "print(\"QUESTION:\")\n",
        "print(question)\n",
        "print()\n",
        "print(\"ANSWER:\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Df2ORIxFATt",
        "outputId": "1cf294a1-d5c3-4d4d-f92d-3414ebd7c301"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUESTION:\n",
            "MEDIDAS ADMINISTRATIVAS RELACIONADAS A LA CONFIRMACIN DE LA PRESENTACIN DEL REGISTRO MENSUAL DE COMPROBANTES\n",
            "\n",
            "ANSWER:\n",
            "## Medidas administrativas relacionadas a la confirmaci贸n de la presentaci贸n del registro mensual de comprobantes\n",
            "\n",
            "La **Resoluci贸n General DNIT N掳 07 / 2024**, emitida el 27 de marzo de 2024 por el Director Nacional de Ingresos Tributarios de Paraguay, establece medidas administrativas relacionadas a la confirmaci贸n de la presentaci贸n del registro mensual de comprobantes:\n",
            "\n",
            "**Puntos clave:**\n",
            "\n",
            "* **Excepci贸n hasta el 31 de agosto de 2024:**\n",
            "    * La falta de confirmaci贸n del tal贸n de presentaci贸n del registro de comprobantes correspondiente a los ejercicios fiscales cerrados al 31 de diciembre de 2021 y 2022 no constituir谩 incumplimiento.\n",
            "    * La falta de confirmaci贸n del tal贸n de presentaci贸n del registro de comprobantes correspondiente a los periodos fiscales del ejercicio fiscal 2023 no constituir谩 incumplimiento.\n",
            "* **Sanci贸n por contravenci贸n:**\n",
            "    * Hasta el 31 de agosto de 2024 no ser谩 aplicable la sanci贸n por contravenci贸n mencionada en el art铆culo 236 de la Ley N掳 125/91.\n",
            "* **Pr贸rroga para la presentaci贸n de los Estados Financieros:**\n",
            "    * Excepcionalmente, el plazo para la presentaci贸n de los Estados Financieros para los ejercicios fiscales cerrados al 31 de diciembre de 2021 y 2022 se prorroga hasta agosto de 2024.\n",
            "    * Los referidos informes deber谩n presentarse conforme al Calendario de Vencimientos de Declaraciones Juradas.\n",
            "    * Los plazos para la presentaci贸n de los Estados Financieros para aquellos contribuyentes del IRE con fecha de cierre de ejercicio fiscal diferente al 31 de diciembre de 2023 se mantienen vigentes.\n",
            "\n",
            "**Es importante destacar que estas medidas son excepcionales y solo se aplican hasta el 31 de agosto de 2024.** A partir de esa fecha, se volver谩 a aplicar la normativa vigente con respecto a la confirmaci贸n de la presentaci贸n del registro mensual de comprobantes y las sanciones por incumplimiento.\n",
            "\n",
            "**Para m谩s informaci贸n, se recomienda consultar la Resoluci贸n General DNIT N掳 07 / 2024 en su totalidad.**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Ask your tuned model\n",
        "\n",
        "If you want to tune a model, follow the [**Fine-tune an LLM model** tutorial](https://console.cloud.google.com/products/solutions/deployments?walkthrough_id=panels--sic--generative-ai-knowledge-base_toc).\n",
        "\n",
        "First, find the tuning job ID for your tuned model."
      ],
      "metadata": {
        "id": "XyLNJ6fvXl1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.tuning import sft\n",
        "\n",
        "for tuning_job in sft.SupervisedTuningJob.list():\n",
        "    model_name = tuning_job.gca_resource.tuned_model_display_name\n",
        "    tuning_job_id = tuning_job.resource_name\n",
        "    print(f\"{model_name}: {tuning_job_id}\")"
      ],
      "metadata": {
        "id": "BAqaEdgY8_MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy your tuning job ID and paste it below.\n",
        "Don't forget to run the cell to define the `tuning_job_id` variable."
      ],
      "metadata": {
        "id": "OwXchBOF_rjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuning_job_id = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8dwbv-Fm_D8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.generative_models import GenerativeModel\n",
        "from vertexai.preview import tuning\n",
        "from vertexai.preview.tuning import sft\n",
        "\n",
        "tuning_job = sft.SupervisedTuningJob(tuning_job_id)\n",
        "assert tuning_job.tuned_model_endpoint_name, \"Please wait until the tuning job finishes.\"\n",
        "\n",
        "tuned_model = GenerativeModel(\n",
        "    model_name=tuning_job.tuned_model_endpoint_name,\n",
        "    system_instruction=context,\n",
        ")\n",
        "answer = tuned_model.generate_content(question).text\n",
        "\n",
        "print(\"QUESTION:\")\n",
        "print(question)\n",
        "print()\n",
        "print(\"ANSWER:\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgXqwCDq8wAf",
        "outputId": "ffa56982-7c67-4df9-e1b9-51bd94afc561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUESTION:\n",
            "What are LFs and why are they useful?\n",
            "\n",
            "ANSWER:\n",
            "Lexical functions (LFs) are functions that operate on lexemes. They are useful because they can be used to generate synonyms.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}