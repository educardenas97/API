{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/educardenas97/API/blob/master/notebooks/model-predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#    https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "l6nGHoRo3mym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI Knowledge Base model predictions\n",
        "\n",
        "To run this notebook, make sure you have uploaded at least one document into your knowledge base.\n",
        "\n",
        "> ⭐️ If you haven't, follow the [**Uploading documents and query model** tutorial](https://console.cloud.google.com/products/solutions/deployments?walkthrough_id=panels--sic--generative-ai-knowledge-base_toc).\n",
        "\n",
        "Before you begin, make sure all the dependencies are installed."
      ],
      "metadata": {
        "id": "PQFrKlY5Yi2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform google-cloud-firestore"
      ],
      "metadata": {
        "id": "W9C3mHjIiZn1",
        "outputId": "c9784442-04df-4434-92ca-2301f8254d50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.70.0)\n",
            "Requirement already satisfied: google-cloud-firestore in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.13.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.9.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-firestore) (2.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "A **Large Language Model (LLM)** can be very good at answering general questions.\n",
        "But it might not do as well to answer questions from your documents on its own.\n",
        "\n",
        "The LLM will answer only from what it learned from its _training dataset_.\n",
        "Your documents might include information or words that weren't on that dataset.\n",
        "Or they might be used in a different or more specialized context.\n",
        "\n",
        "This is where **Vector Search** comes into place.\n",
        "Each time you upload a document, the Cloud Function webhook processes it.\n",
        "When a document is processed, each individual page is _indexed_.\n",
        "This allows us to not only find documents, but the specific pages.\n",
        "\n",
        "The relevant pages can then be used as _context_ for the LLM to answer the question.\n",
        "This _grounds_ the model to answer questions based on the documents only.\n",
        "Without this, the model might give wrong answers, or _hallucinations_."
      ],
      "metadata": {
        "id": "tXeqwSesfIjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My Google Cloud resources\n",
        "\n",
        "Fill in your project ID, the\n",
        "[Google Cloud location](https://cloud.google.com/about/locations)\n",
        "you want to use, and your\n",
        "Vector Search index endpoint ID.\n",
        "If you followed the tutorial, the deployed index ID should be `deployed_index`, otherwise change it to the ID you chose.\n",
        "\n",
        "You can find your Vector Search index endpoint ID in the [Index endpoints tab](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints).\n",
        "\n",
        "> 💡 The Vector Search index endpoint ID looks like a number, like `1234567890123456789`.\n",
        "\n",
        "Run the following cell to set up your resources and authenticate to your account."
      ],
      "metadata": {
        "id": "nZeNBhYcknZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from google.colab import auth\n",
        "\n",
        "project_id = \"legal-bot-433022\" # @param {type:\"string\"}\n",
        "location = \"us-central1\" # @param {type:\"string\"}\n",
        "index_endpoint_id = \"2675397663402229760\" # @param {type:\"string\"}\n",
        "deployed_index_id = \"knowledge_base_index_deplo_1731351552266\" # @param {type:\"string\"}\n",
        "\n",
        "auth.authenticate_user(project_id=project_id)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4EctJVdOj0MY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is to initialize the Vertex AI client library using the location of your choice."
      ],
      "metadata": {
        "id": "1P7apRRQabq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "vertexai.init(location=location)\n",
        "aiplatform.init(location=location)"
      ],
      "metadata": {
        "id": "nkPB50oClSD6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get text embeddings\n",
        "\n",
        "You can use the Gecko model to get embeddings from text.\n",
        "For more information, see the\n",
        "[Get text embeddings](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings)\n",
        "page."
      ],
      "metadata": {
        "id": "5rDc4RataxgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
        "\n",
        "def get_text_embedding(text: str) -> list[float]:\n",
        "    task = 'RETRIEVAL_DOCUMENT'\n",
        "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko\")\n",
        "    return model.get_embeddings([TextEmbeddingInput(text, task)])[0].values\n",
        "\n",
        "\n",
        "# Convert the question into an embedding.\n",
        "#question = \"Leyes sobre el impuesto selectivo al consumo\"\n",
        "question = \"¿Qué dice La Ley N° 6380/2019?\"\n",
        "question_embedding = get_text_embedding(question)\n",
        "print(f\"Embedding dimensions: {len(question_embedding)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ97FaoBdO_8",
        "outputId": "9a1c78d1-9b8e-4741-bd52-2eb7c76517f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dimensions: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find document context\n",
        "\n",
        "All the documents you have processed have been indexed into your Vector Search index.\n",
        "You can query for the closest embeddings to a given embedding from your Vector Search index endpoint.\n",
        "\n",
        "> 💡 If you haven't processed any documents yet, you won't get any results."
      ],
      "metadata": {
        "id": "vnJfXPXAb-1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import groupby\n",
        "\n",
        "def find_document(question: str, index_endpoint_id: str, deployed_index_id: str) -> tuple[str, int]:\n",
        "    # Get embeddings for the question.\n",
        "    embedding = get_text_embedding(question)\n",
        "\n",
        "    # Find the closest point from the Vector Search index endpoint.\n",
        "    endpoint = aiplatform.MatchingEngineIndexEndpoint(index_endpoint_id)\n",
        "    point = endpoint.find_neighbors(\n",
        "        deployed_index_id=deployed_index_id,\n",
        "        queries=[embedding],\n",
        "        num_neighbors=1,\n",
        "    )[0][0]\n",
        "\n",
        "    # Get the document name and page number from the point ID.\n",
        "    (filename, page_number) = point.id.split(':', 1)\n",
        "    return (filename, int(page_number))\n",
        "\n",
        "# Query the Vector Search index for the most relevant page.\n",
        "(filename, page_number) = find_document(question, index_endpoint_id, deployed_index_id)\n",
        "print(f\"{filename=} {page_number=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxLfbjSLeaIh",
        "outputId": "04ea3769-3d04-4fd3-ba12-9cf2f2e70e4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename='RESOLUCIÓN N° 07 - 2024.pdf' page_number=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get document text\n",
        "\n",
        "When documents were processed, their text was stored in Firestore as well.\n",
        "The Vector Search query returned the relevant documents with their page numbers.\n",
        "With this you can download the document's pages and give only the most relevant page to the model."
      ],
      "metadata": {
        "id": "BzRC13xdeK5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import firestore\n",
        "\n",
        "def get_document_text(filename: str, page_number: int) -> str:\n",
        "    db = firestore.Client(database='knowledge-base-database')\n",
        "    doc = db.collection(\"documents\").document(filename)\n",
        "    return doc.get().get('pages')[page_number]\n",
        "\n",
        "# Download the document's page text from Firestore.\n",
        "context = get_document_text(filename, page_number)\n",
        "print(f\"{context[:1000]}\\n...\\n...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTJqJg1dfRY5",
        "outputId": "7440db40-cdd3-4ee4-f583-66151186f567"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: RESOLUCIO?N N° 07 - 2024\n",
            "RESOLUCIÓN GENERAL DNIT N° 07 / 2024\n",
            "POR LA CUAL SE DISPONEN MEDIDAS ADMINISTRATIVAS RELACIONADAS A LA CONFIRMACIÓN\n",
            "Asunción, 27 de marzo de 2024\n",
            "VISTO: El Libro V de la Ley N° 125/1991 «Que establece el Nuevo Régimen Tributario» y sus modificacio\n",
            "CONSIDERANDO: Que con el objeto de estandarizar la información a ser presentada a la Administración\n",
            "POR TANTO,\n",
            "EL DIRECTOR NACIONAL DE INGRESOS TRIBUTARIOS\n",
            "RESUELVE:\n",
            "Artículo 1°. - Establecer que excepcionalmente hasta el 31 de agosto de 2024 no constituirá incumplimient\n",
            "a. La falta de confirmación del talón de presentación del registro de comprobantes correspondiente a los e\n",
            "b. La falta de confirmación del talón de presentación del registro de comprobantes correspondiente a los p\n",
            "Durante dicho periodo igualmente se seguirá recibiendo el registro de los comprobantes y la confirmación\n",
            "Artículo 2°. - Establecer que hasta el 31 de agosto de 2024 no será aplicable la sanción por contravención\n",
            "Artículo 3°. - Dispone\n",
            "...\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ask a foundational model\n",
        "\n",
        "With the relevant context ready, you can now make a _prompt_ that includes both the context and the question.\n",
        "\n",
        "Here's Gemini's response.\n",
        "Note that Gemini responds in [Markdown](https://www.markdownguide.org)."
      ],
      "metadata": {
        "id": "5NB2BO0tSBFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "# Ask the foundational model.\n",
        "model = GenerativeModel(\n",
        "    model_name=\"gemini-1.0-pro-002\",\n",
        "    system_instruction=context,\n",
        ")\n",
        "answer = model.generate_content(question).text\n",
        "\n",
        "print(\"QUESTION:\")\n",
        "print(question)\n",
        "print()\n",
        "print(\"ANSWER:\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Df2ORIxFATt",
        "outputId": "1cf294a1-d5c3-4d4d-f92d-3414ebd7c301"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUESTION:\n",
            "MEDIDAS ADMINISTRATIVAS RELACIONADAS A LA CONFIRMACIÓN DE LA PRESENTACIÓN DEL REGISTRO MENSUAL DE COMPROBANTES\n",
            "\n",
            "ANSWER:\n",
            "## Medidas administrativas relacionadas a la confirmación de la presentación del registro mensual de comprobantes\n",
            "\n",
            "La **Resolución General DNIT N° 07 / 2024**, emitida el 27 de marzo de 2024 por el Director Nacional de Ingresos Tributarios de Paraguay, establece medidas administrativas relacionadas a la confirmación de la presentación del registro mensual de comprobantes:\n",
            "\n",
            "**Puntos clave:**\n",
            "\n",
            "* **Excepción hasta el 31 de agosto de 2024:**\n",
            "    * La falta de confirmación del talón de presentación del registro de comprobantes correspondiente a los ejercicios fiscales cerrados al 31 de diciembre de 2021 y 2022 no constituirá incumplimiento.\n",
            "    * La falta de confirmación del talón de presentación del registro de comprobantes correspondiente a los periodos fiscales del ejercicio fiscal 2023 no constituirá incumplimiento.\n",
            "* **Sanción por contravención:**\n",
            "    * Hasta el 31 de agosto de 2024 no será aplicable la sanción por contravención mencionada en el artículo 236 de la Ley N° 125/91.\n",
            "* **Prórroga para la presentación de los Estados Financieros:**\n",
            "    * Excepcionalmente, el plazo para la presentación de los Estados Financieros para los ejercicios fiscales cerrados al 31 de diciembre de 2021 y 2022 se prorroga hasta agosto de 2024.\n",
            "    * Los referidos informes deberán presentarse conforme al Calendario de Vencimientos de Declaraciones Juradas.\n",
            "    * Los plazos para la presentación de los Estados Financieros para aquellos contribuyentes del IRE con fecha de cierre de ejercicio fiscal diferente al 31 de diciembre de 2023 se mantienen vigentes.\n",
            "\n",
            "**Es importante destacar que estas medidas son excepcionales y solo se aplican hasta el 31 de agosto de 2024.** A partir de esa fecha, se volverá a aplicar la normativa vigente con respecto a la confirmación de la presentación del registro mensual de comprobantes y las sanciones por incumplimiento.\n",
            "\n",
            "**Para más información, se recomienda consultar la Resolución General DNIT N° 07 / 2024 en su totalidad.**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Ask your tuned model\n",
        "\n",
        "If you want to tune a model, follow the [**Fine-tune an LLM model** tutorial](https://console.cloud.google.com/products/solutions/deployments?walkthrough_id=panels--sic--generative-ai-knowledge-base_toc).\n",
        "\n",
        "First, find the tuning job ID for your tuned model."
      ],
      "metadata": {
        "id": "XyLNJ6fvXl1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.tuning import sft\n",
        "\n",
        "for tuning_job in sft.SupervisedTuningJob.list():\n",
        "    model_name = tuning_job.gca_resource.tuned_model_display_name\n",
        "    tuning_job_id = tuning_job.resource_name\n",
        "    print(f\"{model_name}: {tuning_job_id}\")"
      ],
      "metadata": {
        "id": "BAqaEdgY8_MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy your tuning job ID and paste it below.\n",
        "Don't forget to run the cell to define the `tuning_job_id` variable."
      ],
      "metadata": {
        "id": "OwXchBOF_rjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuning_job_id = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8dwbv-Fm_D8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.generative_models import GenerativeModel\n",
        "from vertexai.preview import tuning\n",
        "from vertexai.preview.tuning import sft\n",
        "\n",
        "tuning_job = sft.SupervisedTuningJob(tuning_job_id)\n",
        "assert tuning_job.tuned_model_endpoint_name, \"Please wait until the tuning job finishes.\"\n",
        "\n",
        "tuned_model = GenerativeModel(\n",
        "    model_name=tuning_job.tuned_model_endpoint_name,\n",
        "    system_instruction=context,\n",
        ")\n",
        "answer = tuned_model.generate_content(question).text\n",
        "\n",
        "print(\"QUESTION:\")\n",
        "print(question)\n",
        "print()\n",
        "print(\"ANSWER:\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgXqwCDq8wAf",
        "outputId": "ffa56982-7c67-4df9-e1b9-51bd94afc561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUESTION:\n",
            "What are LFs and why are they useful?\n",
            "\n",
            "ANSWER:\n",
            "Lexical functions (LFs) are functions that operate on lexemes. They are useful because they can be used to generate synonyms.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}